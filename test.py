import os
import logging
import json
import re
from datetime import datetime
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from telegram.constants import ChatAction

# KÃ¼tÃ¼phaneler
from google import genai
from google.genai import types as genai_types
from google.genai.errors import APIError as GeminiAPIError

# --- GEREKLÄ° AYARLAR VE LOGLAMA ---

# Token ve AnahtarlarÄ±nÄ±z (DeÄŸerleriniz Koda YerleÅŸtirilmiÅŸtir)
TELEGRAM_BOT_TOKEN = "your token"
LLM_API_KEY = "your key" 
RESTORAN_ADI = "Hafta3 RestoranÄ±"

# Loglama ayarÄ±
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO
)
logger = logging.getLogger(__name__)

# Her kullanÄ±cÄ± iÃ§in konuÅŸma geÃ§miÅŸini (hafÄ±zayÄ±) tutacak yapÄ±
user_conversations = {}

# âš ï¸ GEMINI Ä°STEMCÄ°SÄ°: Anahtar ile baÅŸlatÄ±lÄ±yor
try:
    gemini_client = genai.Client(api_key=LLM_API_KEY)
except Exception as e:
    logger.error(f"Gemini istemcisi baÅŸlatÄ±lÄ±rken hata oluÅŸtu: {e}")
    gemini_client = None

GEMINI_MODEL = "gemini-2.5-flash" 

# --- I. LLM SÄ°STEM PROMPT'U ---

def get_system_prompt():
    """LLM'in rolÃ¼nÃ¼, kurallarÄ±nÄ± ve formatÄ±nÄ± belirleyen prompt'u dÃ¶ndÃ¼rÃ¼r."""
    today_date = datetime.now().strftime('%Y-%m-%d')
    
    prompt = f"""
    Sen, "{RESTORAN_ADI}" iÃ§in bir rezervasyon asistanÄ±sÄ±n.
    GÃ¶revin, kullanÄ±cÄ±dan rezervasyon iÃ§in 3 temel bilgiyi toplamaktÄ±r: TARÄ°H, SAAT ve KÄ°ÅÄ° SAYISI.
    KullanÄ±cÄ±yla doÄŸal bir dille sohbet et.

    KURALLAR:
    1. TÃ¼m bu 3 bilgi (tarih, saat, kiÅŸi sayÄ±sÄ±) netleÅŸtiÄŸinde, baÅŸka HÄ°Ã‡BÄ°R ÅEY YAZMADAN, sadece ve sadece ÅŸu formatta bir JSON objesi dÃ¶ndÃ¼r:
       {{"intent": "check_availability", "date": "YYYY-MM-DD", "time": "HH:MM", "party_size": N}}
    2. EÄŸer bilgiler eksikse (Ã¶rn: "yarÄ±n 3 kiÅŸi" dedi ama saat vermedi), JSON DÃ–NDÃœRME. Eksik olan bilgiyi kibarca iste (Ã¶rn: "Harika, yarÄ±n 3 kiÅŸi iÃ§in. Saat kaÃ§ta gelmeyi dÃ¼ÅŸÃ¼nÃ¼yorsunuz?").
    3. Tarihleri her zaman YYYY-MM-DD formatÄ±na, saatleri HH:MM (24 saat formatÄ±) formatÄ±na Ã§evir. BugÃ¼nÃ¼n tarihi: {today_date}
    4. KullanÄ±cÄ± sohbet ederse ("merhaba", "nasÄ±lsÄ±n"), kibarca cevap ver ve rezervasyon iÃ§in yardÄ±mcÄ± olabileceÄŸini belirt.
    """
    return prompt.strip()


# --- II. REZERVASYON Ä°ÅLEMLERÄ° (Ã–NEMLÄ°: GerÃ§ek API baÄŸlantÄ±sÄ± buraya gelmeli) ---

async def process_reservation_check(details: dict, update: Update):
    """
    LLM'den gelen JSON'u iÅŸler, mÃ¼saitlik kontrolÃ¼nÃ¼ yapar ve sonucu LLM'e geri gÃ¶nderir.
    Bu kÄ±sÄ±m sadece simÃ¼lasyondur.
    """
    try:
        date = details.get("date")
        time = details.get("time")
        party_size = details.get("party_size")
        
        # âš ï¸ SÄ°MÃœLASYON BAÅLANGICI âš ï¸
        if party_size > 6:
            response_to_llm = f"Rezervasyon yapÄ±lamadÄ±: {party_size} kiÅŸi iÃ§in mÃ¼sait masa bulunamadÄ±. LÃ¼tfen daha kÃ¼Ã§Ã¼k bir grup veya baÅŸka bir tarih deneyin."
        else:
            reservation_id = "RZ" + str(hash(date + time + str(party_size)) % 10000)
            masa_adÄ± = "Masa 5 (Pencere KenarÄ±)" 
            customer_name = update.effective_user.first_name or "Misafir"
            final_message = f"""
Harika, **{customer_name}**!
Rezervasyonunuz (No: **{reservation_id}**) baÅŸarÄ±yla oluÅŸturuldu.

Detaylar:
ğŸ“… Tarih: {date}
â° Saat: {time}
ğŸ‘¥ KiÅŸi SayÄ±sÄ±: {party_size}
ğŸ“ Masa: {masa_adÄ±}

Sizi aÄŸÄ±rlamak iÃ§in sabÄ±rsÄ±zlanÄ±yoruz!
            """
            
            await update.message.reply_html(final_message)
            user_id = update.effective_user.id
            if user_id in user_conversations:
                del user_conversations[user_id]
            
            return # Rezervasyon baÅŸarÄ±lÄ±, LLM'i tekrar Ã§aÄŸÄ±rmÄ±yoruz

        return response_to_llm # BaÅŸarÄ±sÄ±zlÄ±k durumunda LLM'e geri bildirim
        
    except Exception as e:
        logger.error(f"Rezervasyon kontrol hatasÄ±: {e}")
        return "ÃœzgÃ¼nÃ¼m, rezervasyon sistemimizde bir hata oluÅŸtu. LÃ¼tfen tekrar deneyin."


# --- III. TELEGRAM Ä°ÅLEYÄ°CÄ° FONKSÄ°YONLARI ---

async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """/start komutuna yanÄ±t verir ve hafÄ±zayÄ± temizler."""
    user_id = update.effective_user.id
    if user_id in user_conversations:
        del user_conversations[user_id]
    
    await update.message.reply_text(
        f'HoÅŸ geldiniz! Ben **{RESTORAN_ADI}** iÃ§in rezervasyon asistanÄ±nÄ±z. '
        f'Size yardÄ±mcÄ± olmaktan mutluluk duyarÄ±m. Rezervasyon yapmak istediÄŸiniz tarih, saat ve kiÅŸi sayÄ±sÄ±nÄ± belirtir misiniz?'
    )

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """KullanÄ±cÄ±nÄ±n her mesajÄ±nÄ± iÅŸler."""
    if not gemini_client:
        await update.message.reply_text("ÃœzgÃ¼nÃ¼m, Gemini API istemcisi doÄŸru ÅŸekilde baÅŸlatÄ±lamadÄ±.")
        return
        
    user_id = update.effective_user.id
    user_message = update.message.text
    
    # KonuÅŸma geÃ§miÅŸini al veya oluÅŸtur
    if user_id not in user_conversations:
        # ğŸŸ¢ DÃœZELTME UYGULANDI: Sistem prompt'u doÄŸru Gemini formatÄ±yla ilk mesaj olarak ekleniyor.
        initial_system_prompt_content = genai_types.Content(
            role="user", 
            parts=[genai_types.Part(text=get_system_prompt())]
        )
        user_conversations[user_id] = [initial_system_prompt_content] 
        
    # KullanÄ±cÄ± mesajÄ±nÄ± geÃ§miÅŸe ekle
    user_conversations[user_id].append(genai_types.Content(role="user", parts=[genai_types.Part(text=user_message)]))
    
    await context.bot.send_chat_action(chat_id=user_id, action=ChatAction.TYPING)
    
    # 2. LLM Ã‡aÄŸrÄ±sÄ± (Gemini'ye Ã¶zgÃ¼)
    try:
        response = gemini_client.models.generate_content(
            model=GEMINI_MODEL,
            contents=user_conversations[user_id],
            config=genai_types.GenerateContentConfig(
                temperature=0.0
            )
        )
        llm_response_text = response.text.strip()
        
    except GeminiAPIError as e:
        logger.error(f"Gemini API Ã‡aÄŸrÄ±sÄ± HatasÄ±: {e}")
        await update.message.reply_text("ÃœzgÃ¼nÃ¼m, Gemini API'ye ulaÅŸÄ±lamÄ±yor (Belki gÃ¼nlÃ¼k limit aÅŸÄ±ldÄ±). LÃ¼tfen tekrar deneyin.")
        return
    except Exception as e:
        logger.error(f"Beklenmedik LLM HatasÄ±: {e}")
        await update.message.reply_text("ÃœzgÃ¼nÃ¼m, bir hata oluÅŸtu.")
        return

    # 3. LLM CevabÄ±nÄ± Ä°ÅŸleme
    
    # import re

    # Kod bloÄŸu ÅŸeklindeki JSON'u yakala (Ã¶rnek: ```json { ... } ```)
    json_match = re.search(r'\{.*\}', llm_response_text, re.DOTALL)
    if json_match:
        json_text = json_match.group(0)
    else:
        json_text = llm_response_text

    if json_text.startswith('{') and json_text.endswith('}'):
        await update.message.reply_html("Rezervasyon detaylarÄ±nÄ±zÄ± kontrol ediyorum, lÃ¼tfen bekleyin... ğŸ½ï¸")
        try:
            reservation_details = json.loads(json_text)
            logger.info(f"LLM JSON Ã‡Ä±ktÄ±sÄ± AldÄ±: {reservation_details}")
            
            llm_feedback = await process_reservation_check(reservation_details, update)
            
            if llm_feedback:
                 # Hata/BaÅŸarÄ±sÄ±zlÄ±k geri bildirimi geldiyse, LLM'e doÄŸal dilde yanÄ±t Ã¼retmesini iste.
                
                # Ã–nceki JSON cevabÄ±nÄ± kaydet (role 'model')
                user_conversations[user_id].append(genai_types.Content(role="model", parts=[genai_types.Part(text=json_text)]))
                
                # Sistemden gelen geri bildirimi 'user' olarak sun
                system_feedback_message = f"Sistemden gelen bilgi: {llm_feedback}. Bu duruma uygun ÅŸekilde mÃ¼ÅŸteriye bilgi ver ve yeni seÃ§enek iste."
                user_conversations[user_id].append(genai_types.Content(role="user", parts=[genai_types.Part(text=system_feedback_message)]))
                
                # LLM'i tekrar Ã§aÄŸÄ±r
                await context.bot.send_chat_action(chat_id=user_id, action=ChatAction.TYPING)
                final_response_obj = gemini_client.models.generate_content(
                    model=GEMINI_MODEL,
                    contents=user_conversations[user_id],
                    config=genai_types.GenerateContentConfig(temperature=0.0)
                )
                final_response_text = final_response_obj.text.strip()
                await update.message.reply_html(final_response_text)
                user_conversations[user_id].append(genai_types.Content(role="model", parts=[genai_types.Part(text=final_response_text)]))

        except json.JSONDecodeError:
            # GeÃ§ersiz JSON ise, LLM'in cevabÄ±nÄ± normal metin olarak gÃ¶nder
            await update.message.reply_html(llm_response_text)
            user_conversations[user_id].append(genai_types.Content(role="model", parts=[genai_types.Part(text=llm_response_text)]))
        
    else:
        # LLM eksik bilgi istedi veya sohbet etti
        await update.message.reply_html(llm_response_text)
        user_conversations[user_id].append(genai_types.Content(role="model", parts=[genai_types.Part(text=llm_response_text)]))


def main():
    """Botu Ã§alÄ±ÅŸtÄ±rÄ±r."""
    if not gemini_client:
        print("Gemini istemcisi baÅŸlatÄ±lamadÄ±. LÃ¼tfen LLM_API_KEY deÄŸerinizi kontrol edin.")
        return

    # Telegram UygulamasÄ±nÄ± OluÅŸturma
    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()

    # Komut ve Mesaj Ä°ÅŸleyicileri
    application.add_handler(CommandHandler("start", start_command))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    # Botu baÅŸlat
    print(f"ğŸ¤– {RESTORAN_ADI} Botu (Gemini) Ã§alÄ±ÅŸÄ±yor...")
    application.run_polling(poll_interval=3)

if __name__ == '__main__':
    main()
